{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pravash Ranjan\\Desktop\\Globsyn\\dataset\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/Globsyn/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import feature_selection\n",
    "from sklearn import tree\n",
    "from sklearn import utils\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import feature_selection\n",
    "from sklearn import ensemble\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Interview.csv\")\n",
    "df.drop([\"Unnamed: 23\",\"Unnamed: 24\",\"Unnamed: 25\",\"Unnamed: 26\",\"Unnamed: 27\"],axis=1,inplace=True)\n",
    "df.columns=[\"date\",\"client\",\"industry\",\"location\",\"position\",\"skills\",\"inter_type\",\"ID\",\"gender\",\"curr_location\",\"job_location\",\n",
    "           \"venue\",\"native_location\",\"permission\",\"hope\",\"three_hours\",\"alt_number\",\"resume\",\"clear_about_venue\",\"letter\",\"expected\",\n",
    "           \"observed\",\"married\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date=df.date.str.replace(\" \",\"\")\n",
    "df.date=df.date.str.replace(r'\\d\\d\\d\\d&\\d\\d\\.\\d\\d\\w\\w',\"2016\")\n",
    "df.date=df.date=df.date.str.replace(\"/\",\".\")\n",
    "df.date=df.date.str.replace(r'\\WApr\\W',\".04.\")\n",
    "df.date=df.date.str.replace('Apr',\".04.\")\n",
    "df.date=df.date.str.replace(r'\\d\\d\\d\\d&\\d\\.\\d\\d\\w\\w',\"2016\")\n",
    "df.date=df.date.str.replace('-',\".\")\n",
    "df.date=df.date.str.replace(r'\\W16',\".2016\")\n",
    "df.date=df.date.str.replace(r'\\W15',\".2015\")\n",
    "df.drop(df[df.date.isnull()].index,inplace=True)\n",
    "import datetime\n",
    "def conv(s):\n",
    "    ar=str(s).split(\".\")\n",
    "    try:\n",
    "        d=datetime.date(int(ar[2]),int(ar[1]),int(ar[0]))\n",
    "    except Exception:\n",
    "        print(len(ar),s)\n",
    "    return (d)\n",
    "df[\"new_date\"]=df.date.apply(conv)\n",
    "df[\"new_date\"]=pd.to_datetime(df.new_date)\n",
    "df.drop(df[df.expected.isnull()].index,inplace=True)\n",
    "df.drop(\"date\",axis=1,inplace=True)\n",
    "df.client.replace({\"Standard Chartered Bank Chennai\":\"Standard Chartered Bank\",\"Aon hewitt Gurgaon\":\"Aon Hewitt\",\"Hewitt\":\"Aon Hewitt\"},inplace=True)\n",
    "df.industry.replace({\"IT Products and Services\":\"IT\",\"IT Services\":\"IT\"},inplace=True)\n",
    "df.location.replace({\"CHENNAI\":\"Chennai\",\"chennai\":\"Chennai\",\"Gurgaonr\":\"Gurgaon\",\"- Cochin- \":\"Cochin\",\"chennai \":\"Chennai\"},inplace=True)\n",
    "df=df[df.new_date<'2019-01-01']\n",
    "df.drop(df[(df.hope.isnull()) & (df.three_hours.isnull()) & (df.alt_number.isnull()) & (df.resume.isnull()) & (df.clear_about_venue.isnull())& (df.letter.isnull())].index,inplace=True)\n",
    "df.observed.replace({\"yes\":\"Yes\",\"yes \":\"Yes\",\"no\":\"No\",\"No \":\"No\",\"NO\":\"No\",\"no \":\"No\"},inplace=True)\n",
    "df.expected.replace({\"yes\":\"Yes\",\"11:00 AM\":\"Yes\",\"10.30 Am\":\"Yes\"},inplace=True)\n",
    "df.letter.replace({\"Havent Checked\":\"No\",\"Need To Check\":\"No\",\"Not sure\":\"No\",\"Yet to Check\":\"No\",\"Not Sure\":\"No\",\"Not yet\":\"No\",\n",
    "                  \"no\":\"No\",\"na\":\"No\",\"yes\":\"Yes\",\"Na\":\"No\"},inplace=True)\n",
    "df.clear_about_venue.replace({\"No- I need to check\":\"No\",\"na\":\"No\",\"yes\":\"Yes\",\"Na\":\"No\",\"no\":\"No\"},inplace=True)\n",
    "df.resume.replace({\"No- will take it soon\":\"No\",\"Not yet\":\"No\",\"na\":\"No\",\"yes\":\"Yes\",\"Na\":\"No\",\"Not Yet\":\"No\"},inplace=True)\n",
    "df.alt_number.replace({\"No I have only thi number\":\"No\",\"na\":\"No\",\"yes\":\"Yes\",\"Na\":\"No\"},inplace=True)\n",
    "df.three_hours.replace({\"No Dont\":\"No\",\"Na\":\"No\",\"yes\":\"Yes\"},inplace=True)\n",
    "df.hope.replace({\"Na\":\"No\",\"yes\":\"Yes\",\"Not Sure\":\"No\",\"cant Say\":\"No\",\"Not sure\":\"No\"},inplace=True)\n",
    "df.permission.replace({\"Not yet\":\"No\",\"Yet to confirm\":\"No\",\"yes\":\"Yes\",\"Na\":\"No\"},inplace=True)\n",
    "for i,s in df.iterrows():\n",
    "    if (df[\"expected\"][i]==\"Uncertain\"):\n",
    "        df[\"expected\"][i]=df[\"observed\"][i]\n",
    "df.permission.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.hope.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.three_hours.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.alt_number.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.resume.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.clear_about_venue.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.letter.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.expected.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.observed.replace({\"Yes\":1,\"No\":0},inplace=True)\n",
    "df.married.replace({\"Married\":1,\"Single\":0},inplace=True)\n",
    "df.drop(df[(df.permission.isnull()) | (df.hope.isnull()) | (df.three_hours.isnull()) | \n",
    "         (df.alt_number.isnull()) | (df.resume.isnull()) | (df.clear_about_venue.isnull()) |\n",
    "        (df.letter.isnull()) | (df.expected.isnull()) | (df.observed.isnull())].index,inplace=True)\n",
    "df.inter_type.replace({\"Scheduled Walkin\":\"Scheduled\",\"Scheduled \":\"Scheduled\",\"Scheduled Walk In\":\"Scheduled\",\"Walkin \":\"Walkin\"},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=df.curr_location\n",
    "ind=df.industry\n",
    "cl=df.client\n",
    "jbl=df.job_location\n",
    "mar=df.married\n",
    "X=df.drop([\"ID\",\"skills\",\"new_date\",\"native_location\",\"curr_location\",\"industry\",\"client\",\"job_location\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.get_dummies(X['position'],prefix='pos',drop_first=True)\n",
    "X = pd.concat([X,pos],axis=1)\n",
    "X.drop(\"position\",axis=1,inplace=True)\n",
    "X.gender.replace({\"Male\":1,\"Female\":0},inplace=True)\n",
    "X.inter_type.replace({\"Scheduled\":1,\"Walkin\":0},inplace=True)\n",
    "typ=pd.get_dummies(X.venue,prefix=\"ven\",drop_first=True)\n",
    "X=pd.concat([X,typ],axis=1)\n",
    "X.drop(\"venue\",axis=1,inplace=True)\n",
    "loc.replace({\"chennai\":\"Chennai\",\"CHENNAI\":\"Chennai\",\"chennai \":\"Chennai\",\"- Cochin- \":\"Cochin\"},inplace=True)\n",
    "jbl.replace({\"- Cochin- \":\"Cochin\"},inplace=True)\n",
    "dum_loc=pd.get_dummies(loc,prefix=\"loc\",drop_first=True)\n",
    "dum_ind=pd.get_dummies(ind,prefix=\"ind\",drop_first=True)\n",
    "dum_jbl=pd.get_dummies(jbl,prefix=\"jbl\",drop_first=True)\n",
    "X=pd.concat([X,dum_loc,dum_ind,dum_jbl],axis=1)\n",
    "X.drop(\"location\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X.observed\n",
    "X.drop(\"observed\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision with  1 features 0.7441860465116279\n",
    "Precision with  2 features 0.7458379578246392\n",
    "Precision with  6 features 0.7441860465116279\n",
    "Precision with  6 features 0.7441860465116279\n",
    "Precision with  6 features 0.7441860465116279\n",
    "Precision with  6 features 0.7441860465116279\n",
    "Precision with  16 features 0.7458379578246392\n",
    "Precision with  16 features 0.7458379578246392\n",
    "Precision with  16 features 0.7458379578246392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trying():\n",
    "    lr=LogisticRegression()\n",
    "    #nb_G=naive_bayes.GaussianNB()\n",
    "    nb_B=naive_bayes.BernoulliNB()\n",
    "    nb_M=naive_bayes.MultinomialNB()\n",
    "    rf=ensemble.RandomForestClassifier()\n",
    "    m=[rf]\n",
    "    s=[\"Random Forest\"]\n",
    "    for j in range(0,len(m)):\n",
    "        print(s[j])\n",
    "        model=m[j]\n",
    "        for i in range(1,10):\n",
    "            rfecv=feature_selection.RFECV(estimator=model,min_features_to_select=i,cv=5,scoring=\"precision\")\n",
    "            rfecv.fit(X,y)\n",
    "            cols=X.columns[rfecv.get_support()]\n",
    "            X_=X[cols]\n",
    "            rfecv.fit(X_,y)\n",
    "            \n",
    "            #model.fit(X_,y)\n",
    "            print(\"Precision with \",len(cols),\"features\",metrics.precision_score(y,rfecv.predict(X_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Precision with  8 features 0.7441860465116279\n",
      "Precision with  2 features 0.7441860465116279\n",
      "Precision with  23 features 0.755079006772009\n",
      "Precision with  9 features 0.7436464088397791\n",
      "Precision with  16 features 0.7600459242250287\n",
      "Precision with  17 features 0.7447280799112098\n",
      "Precision with  14 features 0.7548240635641317\n",
      "Precision with  19 features 0.7565415244596132\n",
      "Precision with  16 features 0.7591324200913242\n"
     ]
    }
   ],
   "source": [
    "trying()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
